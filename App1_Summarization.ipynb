{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q"
      ],
      "metadata": {
        "id": "LRE8bTaF7Wxo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fu1eymLF6z26"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51ytTku3_WGC",
        "outputId": "65f6e3d5-66f0-42d8-cf78-b91a1823b5f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 20 09:35:10 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
      ],
      "metadata": {
        "id": "K4atKO7mGfaA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(input):\n",
        "    output = summarizer(input, max_length=130, min_length=30, do_sample=False)\n",
        "    return output"
      ],
      "metadata": {
        "id": "sw3ESs6EHCqb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"\"\"\n",
        "First off all thank you so much for this opertunity, I'm Aakash Kumar Singh. I graduated from the Indian Institute of Technology (IIT), Bombay.\n",
        "My home town in siwan distric of Bihar, I've interest in data science and artificial intelligence field,\n",
        "\n",
        "I've been working as an Associate Data Scientist at HDFC Life, where I've done some interesting stuff. For instance, I built a smart system that can read documents and tell what they are with an accuracy of 96% on test datasets. I also made a system that can look at ID cards like Aadhaar cards and passports and pull out the important information from them.\n",
        "\n",
        "I also got into health tech, where I made a system to predict heart rates and blood pressure from videos of people's faces. It's a bit like magic!\n",
        "\n",
        "In the world of email, I made a computer program that's really good at spotting spam emails with a 98.99% accuracy rate. Plus, I worked on a miss-sell project that can predict things with 98.69% accuracy.\n",
        "\n",
        "I'm good with technical skills like Python, OpenCV, pandas, NumPy, AWS, and TensorFlow, and I've taken some courses in things like machine learning, Deep Learning, computer vision and natural language processing.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "summarize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg7MwMwqNoqz",
        "outputId": "8501fcaf-a7c4-4551-b814-e2e9bb25e32d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': \"Aakash Kumar Singh is an Associate Data Scientist at HDFC Life. He built a system that can read documents and tell what they are with an accuracy of 96% on test datasets. He also made a system to predict heart rates and blood pressure from videos of people's faces.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(text)[0]"
      ],
      "metadata": {
        "id": "Cjldz_h8Ny0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75550b71-4bea-4d48-8d26-1cd30a4d9999"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary_text': \"Aakash Kumar Singh is an Associate Data Scientist at HDFC Life. He built a system that can read documents and tell what they are with an accuracy of 96% on test datasets. He also made a system to predict heart rates and blood pressure from videos of people's faces.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(input):\n",
        "    output = summarizer(input, max_length=130, min_length=30, do_sample=False)\n",
        "    return output[0]['summary_text']"
      ],
      "metadata": {
        "id": "8CS21q0KHLJ8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(text)"
      ],
      "metadata": {
        "id": "nonTq7SCJfp1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3bfa782a-7e2e-4928-c4cb-5f75625ef9a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Aakash Kumar Singh is an Associate Data Scientist at HDFC Life. He built a system that can read documents and tell what they are with an accuracy of 96% on test datasets. He also made a system to predict heart rates and blood pressure from videos of people's faces.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "7hXUSz9sKvWZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(input):\n",
        "    output = summarizer(input, max_length=130, min_length=30, do_sample=False)\n",
        "    return output[0]['summary_text']\n",
        "\n",
        "\n",
        "import gradio\n",
        "\n",
        "gradio.Interface(summarize, \"text\", \"text\").launch(share=True)"
      ],
      "metadata": {
        "id": "Ngo7B-oZKMwL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "6dc9017e-6969-4929-adc1-fa670f6bab27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://2bb8ad2957b7b765b6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2bb8ad2957b7b765b6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradio.close_all()"
      ],
      "metadata": {
        "id": "u5B7dydcKb5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba7b0d8b-90a8-4e52-ea4f-e12723ad1522"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WGzSVSUuLYaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}